{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'content from Resume:Skills required for a Machine Learning Engineer typically include proficiency in programming languages such as Python, R, Java, and C++, knowledge of machine learning algorithms, experience with data visualization tools like Tableau, familiarity with big data tools and ecosystems like Hadoop and Spark, expertise in data mining, statistical modeling, and deep learning techniques, as well as the ability to work with large datasets, develop predictive models, and collaborate with domain experts for relevant data analysis. content from Jobs postings:Skills required for a Machine Learning Engineer include expertise in Python and its machine learning and image processing libraries, experience in building and implementing production scale Machine Learning models, extensive experience in PyTorch deep learning framework, solid understanding of foundational statistics concepts and ML algorithms, good theoretical and practical knowledge of deep learning architectures such as LSTM, RNN, CNN, and Transformer based models, familiarity with scientific computing libraries like numpy, pandas, scikit, and image processing libraries such as OpenCV and scikit-image, experience in containerizing Deep Learning models for deployment, proficiency with SQL and NoSQL databases and ETL tools, familiarity with Git, strong cross-team communication and collaboration skills, attention to detail, data accuracy, and quality of output. Additional skills that are considered a bonus include experience in image processing, applying image enhancement and segmentation on medical images, prior experience with MLOps like MLFlow, background in Life Science, experience in privacy preserving or federated machine learning, and research publications in ML/AI-related fields.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.indices.postprocessor import SimilarityPostprocessor\n",
    "from llama_index.core.indices.loading import load_index_from_storage\n",
    "from llama_index.core.storage.storage_context import StorageContext\n",
    "from llama_index.core.response.pprint_utils import pprint_response\n",
    "\n",
    "# jobs \n",
    "persist_dir_j = './storageDataJobs' \n",
    "data_j  = './DataJobs'\n",
    "# Resume \n",
    "persist_dir_r = './storageDataResume'\n",
    "data_r = './DataResume'\n",
    "\n",
    "\n",
    "storage_context_r = StorageContext.from_defaults(persist_dir=persist_dir_r)\n",
    "storage_context_j = StorageContext.from_defaults(persist_dir=persist_dir_j)\n",
    "\n",
    "index_r = load_index_from_storage(storage_context=storage_context_r)\n",
    "index_j = load_index_from_storage(storage_context=storage_context_j)\n",
    "\n",
    "retriever_r = VectorIndexRetriever(index=index_r,similarity_top_k=5)\n",
    "retriever_j = VectorIndexRetriever(index=index_j,similarity_top_k=5)\n",
    "\n",
    "postprocessor = SimilarityPostprocessor(similarity_cutoff=0.75)\n",
    "\n",
    "query_engine_j = RetrieverQueryEngine(retriever=retriever_j,node_postprocessors=[postprocessor])\n",
    "query_engine_r = RetrieverQueryEngine(retriever=retriever_r,node_postprocessors=[postprocessor])\n",
    "\n",
    "query = \"what skills are requred for machine learning engineer ?\"\n",
    "def query_pipleline(question):\n",
    "    response_j = query_engine_j.query(question)\n",
    "    response_r = query_engine_r.query(question)\n",
    "    prompt_j = \" content from Jobs postings:\"\n",
    "    prompt_r = \"content from Resume:\"\n",
    "    \n",
    "    return prompt_r + response_r.response + prompt_j + response_j.response\n",
    "\n",
    "\n",
    "query_pipleline(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_list = [\n",
    "    \"what skills are requred for machine learning engineer ?\",\n",
    "    \"can you recommend me a course ?\",\n",
    "    \"can you recommend me a course for cooking ?\",\n",
    "    \"how should i imporve my managment skills ?\",\n",
    "    \"What skills are missing in my resume ?\",\n",
    "    \"how can i improve my resume ?\"\n",
    "]\n",
    "for query in query_list : \n",
    "    print('user: ',query)\n",
    "    print('model: ',end=\"\")\n",
    "    print(query_pipleline(query))\n",
    "    print('-'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing some key skills and experience that are often required in the job market. It seems like you may need to update your resume to include expertise in cloud computing platforms like AWS or Azure, experience with data engineering tools such as Apache Kafka or Apache Airflow, proficiency in data governance and data quality management, familiarity with containerization technologies like Docker or Kubernetes, and knowledge of advanced analytics techniques like reinforcement learning or time series forecasting.\n",
      "\n",
      "Additionally, it appears that you should consider gaining skills related to specific programming languages and platforms mentioned in job descriptions, such as Kafka, Spark, Redis, Flink, Trino/Presto, Hadoop, Visier Platform, One Model, Azure Synapse Analytics, and SQL. Experience with containerizing Deep Learning models, SQL and NoSQL databases, ETL tools, Git, and image processing libraries like OpenCV and scikit-image could also be beneficial.\n",
      "\n",
      "Moreover, having knowledge in MLOps, image processing, a background in Life Sciences, privacy-preserving or federated machine learning, and research publications in ML/AI-related fields would further enhance your profile and increase your competitiveness in the job market. Consider updating your resume and acquiring these skills to improve your chances of landing relevant job opportunities.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "user_input = \"what skills are missing in my resume ?\"\n",
    "\n",
    "openai.api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "client = openai.OpenAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are \"},\n",
    "        {\"role\": \"user\", \"content\": query_pipleline(user_input)},\n",
    "    ],\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    max_tokens=1024,\n",
    "    n=1,\n",
    "    stop=None,\n",
    "    temperature=0.5\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# She is skilled in both frontend and backend coding, with related experience. \n",
    "# Additionally, she has extensive experience, making her eligible for lead or staff roles. \n",
    "# It's not me who decided that, but rather the analytics behind it, which utilize machine learning. \n",
    "# We have processed and analyzed the data, provided values for experience and skills, and generated a recommendation list based on it.\n",
    "# the recommendation list is then presented to the user and you can notice that senior backend engineer is listed above staff backend engineer.\n",
    "\n",
    "# I am sure Jessica Claire is not confident about applying for the job, which is why she approached the AI counseling advisor.\n",
    "# thats where she along with us will find out the reason why.\n",
    "# And also if  there is any improvement or courses that she can take.\n",
    "\n",
    "\n",
    "# We have developned a demo version and a deployable version.\n",
    "# the difference is that the demo version is limited to only one user, the location of search and the number of jobs visited.\n",
    "# the fuel stack has no limitations.\n",
    "# this is puerly for demonstration purposes and ease the computatinonal power.\n",
    "# but the based querrying engine, llamaindexing, embeding  & logic for APi calls will remain the same.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nWhy is embedding important here?\\n - Embeddings are crucial because they significantly reduce resource usage and costs.\\n - Sending the entire document to OpenAI each time is resource-intensive and expensive.\\n - Although tokenizing incurs a cost, it ultimately lowers expenses for multiple calls.\\n - Embeddings compact the document, reducing data sent and processed, saving resources.\\n \\n'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Why is embedding important here?\n",
    " - Embeddings are crucial because they significantly reduce resource usage and costs.\n",
    " - Sending the entire document to OpenAI each time is resource-intensive and expensive.\n",
    " - Although tokenizing incurs a cost, it ultimately lowers expenses for multiple calls.\n",
    " - Embeddings compact the document, reducing data sent and processed, saving resources.\n",
    " \n",
    "'''\n",
    "'''\n",
    "also the token size errors\n",
    "and no data leaves yur device.\n",
    "easy to build a federated learning model.\n",
    "'''\n",
    "\n",
    "# document and sentance embedding\n",
    "# flowise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backup text code : \n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import os\n",
    "import openai\n",
    "\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.indices.postprocessor import SimilarityPostprocessor\n",
    "from llama_index.core.indices.loading import load_index_from_storage\n",
    "from llama_index.core.storage.storage_context import StorageContext\n",
    "from llama_index.core.response.pprint_utils import pprint_response\n",
    "\n",
    "\n",
    "client = openai.OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# jobs \n",
    "persist_dir_j = './storageDataJobs' \n",
    "data_j  = './DataJobs'\n",
    "# Resume \n",
    "persist_dir_r = './storageDataResume'\n",
    "data_r = './DataResume'\n",
    "\n",
    "\n",
    "storage_context_r = StorageContext.from_defaults(persist_dir=persist_dir_r)\n",
    "storage_context_j = StorageContext.from_defaults(persist_dir=persist_dir_j)\n",
    "\n",
    "index_r = load_index_from_storage(storage_context=storage_context_r)\n",
    "index_j = load_index_from_storage(storage_context=storage_context_j)\n",
    "\n",
    "retriever_r = VectorIndexRetriever(index=index_r,similarity_top_k=5)\n",
    "retriever_j = VectorIndexRetriever(index=index_j,similarity_top_k=5)\n",
    "\n",
    "postprocessor = SimilarityPostprocessor(similarity_cutoff=0.75)\n",
    "\n",
    "query_engine_j = RetrieverQueryEngine(retriever=retriever_j,node_postprocessors=[postprocessor])\n",
    "query_engine_r = RetrieverQueryEngine(retriever=retriever_r,node_postprocessors=[postprocessor])\n",
    "\n",
    "\n",
    "def load_resume():\n",
    "    resume = pd.read_csv('./DataResume/ResumeDisplay.csv')\n",
    "    return resume\n",
    "\n",
    "def load_jobs():\n",
    "    # Finding similar jobs\n",
    "    jobs = pd.read_csv('./DataJobs/JobsDisplay.csv')\n",
    "    return jobs\n",
    "\n",
    "\n",
    "def query_pipleline(question):\n",
    "    \n",
    "    start = \"Start with my name from resume name. like hi Jessica.\\n \"\n",
    "    response_j = query_engine_j.query(question)\n",
    "    response_r = query_engine_r.query(question)\n",
    "    prompt_j = \" content from Jobs applied:\"\n",
    "    prompt_r = \"content from Resume:\"\n",
    "    \n",
    "    return start + prompt_r + response_r.response + prompt_j + response_j.response\n",
    "\n",
    "\n",
    "\n",
    "# Function to clean HTML content and extract text\n",
    "\n",
    "def chat_with_bot(user_question):\n",
    "    \"\"\"\n",
    "    Chat with an AI consulting bot based on the user's resume and selected jobs.\n",
    "    \n",
    "    Parameters:\n",
    "    - user_question: The question asked by the user.\n",
    "    - resume: A DataFrame containing the user's resume information.\n",
    "    - applied_jobs: A DataFrame containing the selected jobs information.\n",
    "    \"\"\"\n",
    "\n",
    "    # Query the OpenAI API with the prompt\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are an experienced and deligent career consultant. If the question is about a job or career advice, You respond with very short answers and do not entertain answering to other questions.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": query_pipleline(user_question)\n",
    "            }\n",
    "        ],\n",
    "        temperature=0.1,\n",
    "        max_tokens=512,\n",
    "        stop=None,\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def display_resume(resume):\n",
    "    st.subheader(\"Resume\")\n",
    "    raw_html = resume.iloc[0]['html']\n",
    "    st.write(raw_html, unsafe_allow_html=True)\n",
    "\n",
    "\n",
    "def display_job_html(raw_html):\n",
    "    st.markdown(\n",
    "        f'<a href=\"{raw_html}\" target=\"_blank\">Open Job Page</a>',\n",
    "        unsafe_allow_html=True\n",
    "    )\n",
    "\n",
    "\n",
    "def main():\n",
    "    st.title(\"Career Adviser - powered by GPT\")\n",
    "    resume = load_resume()\n",
    "\n",
    "    if not resume.empty:\n",
    "        jobs = load_jobs()\n",
    "\n",
    "        st.sidebar.subheader(\"Recent Jobs Visited\")\n",
    "\n",
    "        # Initialize a list to keep track of selected jobs based on toggle state\n",
    "        selected_jobs = []\n",
    "\n",
    "        # Create a toggle switch for each job\n",
    "        for i, job in jobs.iterrows():\n",
    "            # Use a unique key for each toggle to maintain state independently\n",
    "            toggle = st.sidebar.toggle(f\"{job['Job_title']} - {job['Company']}\", key=f\"toggle_{i}\")\n",
    "            if toggle:\n",
    "                # If the toggle is 'on', add the job to the list of selected jobs\n",
    "                selected_jobs.append(job)\n",
    "\n",
    "\n",
    "        if selected_jobs:\n",
    "            st.subheader(\"Selected Jobs\")\n",
    "            # Display details for each selected job with URLs\n",
    "            for i, job in enumerate(selected_jobs, 1):\n",
    "                # Generate URL for each job\n",
    "                job_url = job['url']\n",
    "                st.write(f\"{i}) [{job['Job_title']} at {job['Company']}](<{job_url}>)\")\n",
    "        else:\n",
    "            display_resume(resume)  \n",
    "\n",
    "        # Example: Displaying the chat interface (Assuming chat_with_bot function exists)\n",
    "        st.subheader(\"Ask the AI Career Consultant\")\n",
    "        user_question = st.text_input(\"Type your question here:\")\n",
    "\n",
    "        if user_question:\n",
    "            # Convert selected_jobs to DataFrame for compatibility\n",
    "            selected_jobs_df = pd.DataFrame(selected_jobs)\n",
    "            response = chat_with_bot(user_question)\n",
    "            st.text_area(\"Response\", value=response, height=150, disabled=True)\n",
    "\n",
    "    else:\n",
    "        st.write(\"No resume data available.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
